{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import Env, spaces, utils\n",
    "import pygame\n",
    "from typing import Optional\n",
    "from io import StringIO\n",
    "from contextlib import closing\n",
    "from gym.spaces import Discrete\n",
    "from gym.wrappers import FlattenObservation\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env_2048 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2.]\n",
      "[2. 4.]\n",
      "[0. 0. 2. 4.]\n",
      "[]\n",
      "[0. 0. 0. 0.]\n",
      "[]\n",
      "[0. 0. 0. 0.]\n",
      "[]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0, 0.0, 2.0, 4.0]\n",
      "[2.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = BlockDoubleEnv()\n",
    "env.reset()\n",
    "env._boardstate = [[0.0, 2.0, 2.0, 2.0],\n",
    "                    [0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 0.0]]\n",
    "new_state, reward, done, info = env.step(0)\n",
    "print(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[0.0, 0.0, 0.0, 4.0]\n",
      "[2.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "env = BlockDoubleEnv()\n",
    "env.reset()  # reset enviornment to default state\n",
    "score = 0\n",
    "while True:\n",
    "    check = 0\n",
    "    print(env.render())\n",
    "    key = input(\"w,a,s,d\\n\").lower()\n",
    "    if key == \"w\":\n",
    "        action = 3\n",
    "    elif key == \"d\":\n",
    "        action = 0\n",
    "    elif key == \"s\":\n",
    "        action = 1\n",
    "    elif key == \"a\":\n",
    "        action = 2\n",
    "    else:\n",
    "        break\n",
    "    clear_output()\n",
    "    new_state, reward, done, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\work\\2048\\2048_ml.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/work/2048/2048_ml.ipynb#ch0000016?line=7'>8</a>\u001b[0m     env\u001b[39m.\u001b[39mrender()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/work/2048/2048_ml.ipynb#ch0000016?line=8'>9</a>\u001b[0m     action \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39msample()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/work/2048/2048_ml.ipynb#ch0000016?line=9'>10</a>\u001b[0m     new_state, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/work/2048/2048_ml.ipynb#ch0000016?line=10'>11</a>\u001b[0m     score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/work/2048/2048_ml.ipynb#ch0000016?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpisode:\u001b[39m\u001b[39m{\u001b[39;00mturn\u001b[39m}\u001b[39;00m\u001b[39m, Score:\u001b[39m\u001b[39m{\u001b[39;00mreward\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\work\\2048\\env_2048.py:85\u001b[0m, in \u001b[0;36mBlockDoubleEnv.step\u001b[1;34m(self, action, done)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/work/2048/env_2048.py?line=82'>83</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/work/2048/env_2048.py?line=83'>84</a>\u001b[0m             x \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='file:///c%3A/work/2048/env_2048.py?line=84'>85</a>\u001b[0m     shift[key] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpad(row,(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(row)), \u001b[39m'\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/work/2048/env_2048.py?line=86'>87</a>\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrot90(shift, \u001b[39m4\u001b[39m\u001b[39m-\u001b[39mdirection)\n\u001b[0;32m     <a href='file:///c%3A/work/2048/env_2048.py?line=87'>88</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_boardstate \u001b[39m=\u001b[39m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "turns = 2\n",
    "for turn in range(1,turns+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f\"Episode:{turn}, Score:{reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 0.0, 2.0, 0.0]\n",
      "[0.0, 0.0, 2.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "1\n",
      "[2.0, 2.0, 2.0, 0.0]\n",
      "[0.0, 0.0, 4.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "2\n",
      "1\n",
      "[0.0, 4.0, 4.0, 2.0]\n",
      "[0.0, 0.0, 2.0, 4.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "1\n",
      "1\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[2.0, 0.0, 4.0, 2.0]\n",
      "[0.0, 4.0, 2.0, 4.0]\n",
      "\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "[4.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[2.0, 4.0, 2.0, 0.0]\n",
      "[4.0, 2.0, 4.0, 0.0]\n",
      "\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "[4.0, 4.0, 2.0, 0.0]\n",
      "[2.0, 2.0, 4.0, 0.0]\n",
      "[4.0, 2.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "print(env.render())\n",
    "new_state, reward, done, info = env.step(0)\n",
    "score += reward\n",
    "print(env.render())\n",
    "new_state, reward, done, info = env.step(1)\n",
    "score += reward\n",
    "print(env.render())\n",
    "new_state, reward, done, info = env.step(2)\n",
    "score += reward\n",
    "print(env.render())\n",
    "new_state, reward, done, info = env.step(3)\n",
    "score += reward\n",
    "print(env.render())\n",
    "new_state, reward, done, info = env.step(0)\n",
    "score += reward\n",
    "print(env.render())\n",
    "new_state, reward, done, info = env.step(1)\n",
    "score += reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env_2048 import *\n",
    "\n",
    "env = BlockDoubleEnv()\n",
    "#2048 = 2^11\n",
    "number_of_powers = 11\n",
    "STATES = env.size * env.size * (number_of_powers + 1)\n",
    "ACTIONS = env.action_space.n\n",
    "Q = np.zeros((STATES, ACTIONS))  # create a matrix with all 0 values \n",
    "\n",
    "EPISODES = 2000 # how many times to run the enviornment from the beginning\n",
    "MAX_STEPS = 100  # max number of steps allowed for each run of enviornment\n",
    "\n",
    "LEARNING_RATE = 0.81  # learning rate\n",
    "GAMMA = 0.96\n",
    "\n",
    "RENDER = True # if you want to see training set to true\n",
    "\n",
    "epsilon = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\work\\2048\\2048_ml.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/work/2048/2048_ml.ipynb#ch0000003?line=12'>13</a>\u001b[0m   action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(Q[state, :])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/work/2048/2048_ml.ipynb#ch0000003?line=14'>15</a>\u001b[0m next_state, reward, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/work/2048/2048_ml.ipynb#ch0000003?line=16'>17</a>\u001b[0m Q[state, action] \u001b[39m=\u001b[39m Q[state, action] \u001b[39m+\u001b[39m LEARNING_RATE \u001b[39m*\u001b[39m (reward \u001b[39m+\u001b[39m GAMMA \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mmax(Q[next_state, :]) \u001b[39m-\u001b[39m Q[state, action])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/work/2048/2048_ml.ipynb#ch0000003?line=18'>19</a>\u001b[0m state \u001b[39m=\u001b[39m next_state\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/work/2048/2048_ml.ipynb#ch0000003?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m done: \n",
      "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "for episode in range(EPISODES):\n",
    "\n",
    "  state = env.reset()\n",
    "  for _ in range(MAX_STEPS):\n",
    "    \n",
    "    if RENDER:\n",
    "      env.render()\n",
    "\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "      action = env.action_space.sample()  \n",
    "    else:\n",
    "      action = np.argmax(Q[state, :])\n",
    "\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    Q[state, action] = Q[state, action] + LEARNING_RATE * (reward + GAMMA * np.max(Q[next_state, :]) - Q[state, action])\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "    if done: \n",
    "      rewards.append(reward)\n",
    "      epsilon -= 0.001\n",
    "      break  # reached goal\n",
    "\n",
    "print(Q)\n",
    "print(f\"Average reward: {sum(rewards)/len(rewards)}:\")\n",
    "# and now we can see our Q values!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0ec4b0e89c119eb2bf145a02ed567940ed0efbda2b6b4ad1ff613fadcc3a6d7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
